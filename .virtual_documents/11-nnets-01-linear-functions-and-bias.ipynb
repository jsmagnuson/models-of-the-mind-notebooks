





import matplotlib.pyplot as plt
import matplotlib.patches as patches
import numpy as np

def draw_neuron_with_label(ax, pos, neuron_text, label):
    # Drawing a neuron with label and black outline
    circle = patches.Circle(pos, radius=0.15, fill=False, edgecolor='black', linewidth=1.5)
    ax.add_patch(circle)
    ax.text(pos[0], pos[1] + 0.18, label, horizontalalignment='center')
    ax.text(*pos, neuron_text, horizontalalignment='center', verticalalignment='center', color='black')

def draw_connection_with_weight(ax, start, end, weight):
    # Drawing a directed arrow with weight label
    ax.annotate('', xy=end, xytext=start, arrowprops=dict(arrowstyle='->'))
    mid = ((start[0] + end[0]) / 2, (start[1] + end[1]) / 2)
    
    # Calculate angle for text rotation
    dx, dy = end[0] - start[0], end[1] - start[1]
    angle = np.degrees(np.arctan2(dy, dx))
    
    ax.text(mid[0], mid[1] + -0.03, weight, horizontalalignment='center', rotation=angle)

# Creating the figure
fig, ax = plt.subplots()
ax.set_xlim(0, 2)
ax.set_ylim(0, 1)
ax.set_aspect('equal')  # Ensures the circles are perfectly round

# Draw Neurons with Labels
draw_neuron_with_label(ax, (1.5, 0.5), '', 'Decision')
draw_neuron_with_label(ax, (0.5, 0.75), '', 'Input 1')
draw_neuron_with_label(ax, (0.5, 0.25), '', 'Input 2')

# Add Threshold Label in Red Below the Decision Node
ax.text(1.5, 0.27, 'Threshold = 1.5', horizontalalignment='center', color='red')

# Draw Connections with Weights
draw_connection_with_weight(ax, (0.65, 0.75), (1.35, 0.55), 'weight1 = 1.0')
draw_connection_with_weight(ax, (0.65, 0.25), (1.35, 0.45), 'weight2 = 1.0')

plt.axis('off')
plt.show()















import network_plotter as netplot
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.patches as patches

plot_width=10.0
plot_height = plot_width
fig_width=plot_width*1.2
fig_height = fig_width
figsize = (fig_width, fig_height) 

# Node / layers definition
layers = [
    ['Input 1', 'Input 2', 'Input 3'],
    ['Hid 1', 'Hid 2', 'Hid 3', 'Hid 4'],
    ['Output']
]

# Generate random weights based on the size of layers
#np.random.seed(0)  # For reproducibility
input_to_hidden_weights = np.random.rand(len(layers[0]), len(layers[1]))  # Weights from inputs to hidden nodes
hidden_to_output_weights = np.random.rand(len(layers[1]))  # Weights from hidden nodes to the output node


# Creating the figure with specified size
fig, ax = plt.subplots(figsize=figsize)
ax.set_xlim(0, fig_width) 
ax.set_ylim(0, fig_height) 
ax.set_aspect('equal', adjustable='box')  # Adjust aspect ratio to fit the plot_width

# Calculate node positions with the specified plot width
node_positions = netplot.calculate_node_positions(layers, plot_width, fig_width, fig_height) # , offset=0.3)

# Draw Neurons with Labels
num_layers = len(layers)
subtext=''
nodetext=''
for i, column in enumerate(layers):
    for node in column:
        pos = node_positions[node]
        if i == num_layers - 1:
            subtext='Decision'
            nodetext = '1.0'
        netplot.draw_neuron_with_label(ax, pos, node, i, num_layers, plot_width=plot_width, subtext=subtext, nodetext=nodetext)

# Draw Connections with Weights
for i, input_node in enumerate(layers[0]):
    for j, hidden_node in enumerate(layers[1]):
        weight = input_to_hidden_weights[i, j]
        netplot.draw_connection_with_weight(ax, node_positions, input_node, hidden_node, weight, show_weight=True, plot_width=plot_width)

# Draw connections from hidden nodes to the decision node
for j, hidden_node in enumerate(layers[1]):
    bow=False
    weight = hidden_to_output_weights[j]
    # uncomment next line to make one connection bowed
    #bow = hidden_node == 'Hid 4'  # Only bow the connection for Hidden4
    netplot.draw_connection_with_weight(ax, node_positions, hidden_node, 'Output', weight, show_weight=True, bow=bow, plot_width=plot_width)
  
netplot.draw_connection_with_weight(ax, node_positions, 'Output', 'Hid 4', 0.44, show_weight=True, bow=True, plot_width=plot_width) # , edge_color='pink')
netplot.draw_connection_with_weight(ax, node_positions, 'Output', 'Hid 1', 0.11, show_weight=True, bow=True, plot_width=plot_width) # , edge_color='pink')
netplot.draw_connection_with_weight(ax, node_positions, 'Hid 1', 'Input 1', 0.01, show_weight=True, bow=True, plot_width=plot_width) # , edge_color='pink')


plt.axis('off')
plt.show()
#print(input_to_hidden_weights)
#print(hidden_to_output_weights)














import network_plotter as netplot
import numpy as np
import matplotlib.pyplot as plt

# Setup for plot
plot_width = 8.0
plot_height = plot_width
fig_width = plot_width * 1.2
fig_height = fig_width
figsize = (fig_width, fig_height)

# Define a simpler network for the OR function
layers_or = [
    ['Input 1', 'Input 2'],
    ['Output']
]

# Set weights for the OR function (both to 1.0)
input_to_output_weights_or = np.array([1.0, 1.0])  # Weights from inputs to the output node

# Creating the figure for the OR network
fig, ax = plt.subplots(figsize=figsize)
ax.set_xlim(0, fig_width)
ax.set_ylim(0, fig_height)
ax.set_aspect('equal', adjustable='box')

# Calculate node positions for the OR network
node_positions_or = netplot.calculate_node_positions(layers_or, plot_width, fig_width, fig_height)

# Draw Neurons with Labels for the OR network
num_layers_or = len(layers_or)
subtext_or = ''
nodetext_or = ''
for i, column in enumerate(layers_or):
    for node in column:
        pos = node_positions_or[node]
        if i == num_layers_or - 1:
            subtext_or = 'Threshold: 0.0'
            nodetext_or = ''
        netplot.draw_neuron_with_label(ax, pos, node, i, num_layers_or, plot_width=plot_width, subtext=subtext_or, nodetext=nodetext_or)

# Draw Connections with Weights for the OR network
for i, input_node in enumerate(layers_or[0]):
    weight = input_to_output_weights_or[i]
    netplot.draw_connection_with_weight(ax, node_positions_or, input_node, 'Output', weight, show_weight=True, plot_width=plot_width)

plt.title('OR network with threshold', x=0.5, y=0.8)
plt.axis('off')
plt.show()






def or_network(input1, input2, weight1=1.0, weight2=1.0, threshold=0.0):
    #weight1, weight2 = 1.0, 1.0  # Weights for the input nodes
    #threshold = 0.0  # Threshold for activation

    # Compute the weighted sum
    weighted_sum = input1 * weight1 + input2 * weight2

    # Check if the weighted sum meets or exceeds the threshold
    myoutput = 1 if weighted_sum > threshold else 0
    return myoutput

# Test the network on all possible input combinations
input_combinations = [(0, 0), (0, 1), (1, 0), (1, 1)]
for inputs in input_combinations:
    output = or_network(*inputs)
    print(f"Input: {inputs}, Output: {output}")






import network_plotter as netplot
import numpy as np
import matplotlib.pyplot as plt

# Setup for the AND network plot
plot_width = 10.0
plot_height = plot_width
fig_width = plot_width * 1.2
fig_height = fig_width
figsize = (fig_width, fig_height)

# Define the network for the AND function
layers_and = [
    ['Input 1', 'Input 2'],
    ['Output']
]

# Set weights for the AND function
# Both inputs need to be 1 to exceed the threshold of 1.5
input_to_output_weights_and = np.array([1.0, 1.0])

# Creating the figure for the AND network
fig, ax = plt.subplots(figsize=figsize)
ax.set_xlim(0, fig_width)
ax.set_ylim(0, fig_height)
ax.set_aspect('equal', adjustable='box')

# Calculate node positions for the AND network
node_positions_and = netplot.calculate_node_positions(layers_and, plot_width, fig_width, fig_height)

# Draw Neurons with Labels for the AND network
num_layers_and = len(layers_and)
subtext_and = ''
nodetext_and = ''
for i, column in enumerate(layers_and):
    for node in column:
        pos = node_positions_and[node]
        if i == num_layers_and - 1:
            subtext_and = 'Threshold: 1.5'
        netplot.draw_neuron_with_label(ax, pos, node, i, num_layers_and, plot_width=plot_width, subtext=subtext_and, nodetext=nodetext_and)

# Draw Connections with Weights for the AND network
for i, input_node in enumerate(layers_and[0]):
    weight = input_to_output_weights_and[i]
    netplot.draw_connection_with_weight(ax, node_positions_and, input_node, 'Output', weight, show_weight=True, plot_width=plot_width)

plt.title('AND network with threshold', x=0.5, y=0.8)
plt.axis('off')
plt.show()






def and_network(input1, input2):
    weight1, weight2 = 1.0, 1.0  # Weights for the input nodes
    threshold = 1.5  # Threshold for activation

    # Compute the weighted sum
    weighted_sum = (input1 * weight1) + (input2 * weight2)

    # Check if the weighted sum meets or exceeds the threshold
    output = 1 if weighted_sum > threshold else 0
    return output

# Test the network on all possible input combinations
input_combinations = [(0, 0), (0, 1), (1, 0), (1, 1)]
for inputs in input_combinations:
    output = and_network(*inputs)
    print(f"Input: {inputs}, Output: {output}")









import numpy as np
import matplotlib.pyplot as plt
import network_plotter as netplot

# Setup for the NAND network plot
plot_width_nand = 10.0
plot_height_nand = plot_width_nand
fig_width_nand = plot_width_nand * 1.2
fig_height_nand = fig_width_nand
figsize_nand = (fig_width_nand, fig_height_nand)

# Define the network for the NAND function
layers_nand = [
    ['Input 1', 'Input 2'],
    ['Output']
]

# Set weights for the NAND function
# Weights need to be negative to represent the NOT operation
# The threshold is set below zero to ensure activation unless both inputs are 1
input_to_output_weights_nand = np.array([-1.0, -1.0])
threshold_nand = -1.5

# Creating the figure for the NAND network
fig, ax = plt.subplots(figsize=figsize_nand)
ax.set_xlim(0, fig_width_nand)
ax.set_ylim(0, fig_height_nand)
ax.set_aspect('equal', adjustable='box')

# Calculate node positions for the NAND network
node_positions_nand = netplot.calculate_node_positions(layers_nand, plot_width_nand, fig_width_nand, fig_height_nand)

# Draw Neurons with Labels for the NAND network
num_layers_nand = len(layers_nand)
subtext_nand = ''
for i, column in enumerate(layers_nand):
    for node in column:
        pos = node_positions_nand[node]
        if i == num_layers_nand - 1:
            subtext_nand = 'Threshold: -1.5'
        netplot.draw_neuron_with_label(ax, pos, node, i, num_layers_nand, plot_width=plot_width_nand, subtext=subtext_nand)

# Draw Connections with Weights for the NAND network
for i, input_node in enumerate(layers_nand[0]):
    weight = input_to_output_weights_nand[i]
    netplot.draw_connection_with_weight(ax, node_positions_nand, input_node, 'Output', weight, show_weight=True, plot_width=plot_width_nand)

plt.title('NAND network with threshold', x=0.5, y=0.8)
plt.axis('off')
plt.show()



# Function to test the NAND network
def nand_network(input1, input2):
    weight1, weight2 = -1.0, -1.0  # Negative weights for the NAND operation
    threshold = -1.5  # Threshold for activation

    # Compute the weighted sum
    weighted_sum = (input1 * weight1) + (input2 * weight2)

    # Check if the weighted sum meets or exceeds the threshold
    output = 1 if weighted_sum >= threshold else 0
    return output

# Test the network on all possible input combinations
input_combinations_nand = [(0, 0), (0, 1), (1, 0), (1, 1)]
test_results_nand = []
for inputs in input_combinations_nand:
    output = nand_network(*inputs)
    test_results_nand.append((inputs, output))
    print(f"Input: {inputs}, Output: {output}")

# alternative, less human-readable way to print results
#test_results_nand








import network_plotter as netplot
import numpy as np
import matplotlib.pyplot as plt

# Setup for the AND network plot
plot_width = 10.0
plot_height = plot_width
fig_width = plot_width * 1.2
fig_height = fig_width
figsize = (fig_width, fig_height)

# Define the network for the AND function
layers_and = [
    ['Input 1', 'Input 2', 'Bias'],
    ['Output']
]

# Set weights for the AND function
# Both inputs need to be 1 to exceed the threshold of 1.5
input_to_output_weights_and = np.array([1.0, 1.0, -1.5])

# Creating the figure for the AND network
fig, ax = plt.subplots(figsize=figsize)
ax.set_xlim(0, fig_width)
ax.set_ylim(0, fig_height)
ax.set_aspect('equal', adjustable='box')

# Calculate node positions for the AND network
node_positions_and = netplot.calculate_node_positions(layers_and, plot_width, fig_width, fig_height)

# Draw Neurons with Labels for the AND network
num_layers_and = len(layers_and)
subtext_and = ''
nodetext_and = ''
for i, column in enumerate(layers_and):
    for node in column:
        pos = node_positions_and[node]
        # if i == num_layers_and - 1:
        #     subtext_and = 'Threshold: 1.5'
        netplot.draw_neuron_with_label(ax, pos, node, i, num_layers_and, plot_width=plot_width, subtext=subtext_and, nodetext=nodetext_and)

# Draw Connections with Weights for the AND network
for i, input_node in enumerate(layers_and[0]):
    weight = input_to_output_weights_and[i]
    netplot.draw_connection_with_weight(ax, node_positions_and, input_node, 'Output', weight, show_weight=True, plot_width=plot_width)

plt.title('AND network with bias node to set threshold', x=0.5, y=0.85)
plt.axis('off')
plt.show()



def and_network_with_bias(input1, input2, bias=1):
    weight_input1, weight_input2 = 1.0, 1.0  # Weights for the input nodes
    weight_bias = -1.5  # Weight for the bias node

    # Compute the weighted sum including the bias
    weighted_sum = input1 * weight_input1 + input2 * weight_input2 + bias * weight_bias

    # The output is 1 if the weighted sum is positive, else 0
    output = 1 if weighted_sum > 0 else 0
    return output

# Test the network with bias on all possible input combinations
input_combinations = [(0, 0), (0, 1), (1, 0), (1, 1)]
for inputs in input_combinations:
    output = and_network_with_bias(*inputs)
    print(f"Input: {inputs}, Output: {output}")









import network_plotter as netplot
import numpy as np
import matplotlib.pyplot as plt

# Setup for the nand network plot
plot_width = 10.0
plot_height = plot_width
fig_width = plot_width * 1.2
fig_height = fig_width
figsize = (fig_width, fig_height)

# Define the network for the nand function
layers_nand = [
    ['Input 1', 'Input 2', 'Bias'],
    ['Output']
]

# Set weights for the nand function
# Both inputs need to be 1 to exceed the threshold of 1.5
input_to_output_weights_nand = np.array([-1.0, -1.0, 1.5])

# Creating the figure for the nand network
fig, ax = plt.subplots(figsize=figsize)
ax.set_xlim(0, fig_width)
ax.set_ylim(0, fig_height)
ax.set_aspect('equal', adjustable='box')

# Calculate node positions for the nand network
node_positions_nand = netplot.calculate_node_positions(layers_nand, plot_width, fig_width, fig_height)

# Draw Neurons with Labels for the nand network
num_layers_nand = len(layers_nand)
subtext_nand = ''
nodetext_nand = ''
for i, column in enumerate(layers_nand):
    for node in column:
        pos = node_positions_nand[node]
        # if i == num_layers_nand - 1:
        #     subtext_nand = 'Threshold: 1.5'
        netplot.draw_neuron_with_label(ax, pos, node, i, num_layers_nand, plot_width=plot_width, subtext=subtext_nand, nodetext=nodetext_nand)

# Draw Connections with Weights for the nand network
for i, input_node in enumerate(layers_nand[0]):
    weight = input_to_output_weights_nand[i]
    netplot.draw_connection_with_weight(ax, node_positions_nand, input_node, 'Output', weight, show_weight=True, plot_width=plot_width)

plt.title('NAND network with bias node to set threshold', x=0.5, y=0.85)
plt.axis('off')
plt.show()









import numpy as np
import matplotlib.pyplot as plt

# Parameters
m = 2  # Slope
b = 30  # Bias

# Data
x = np.linspace(-10, 10, 100)

# Line without bias
y_no_bias = m * x

# Line with bias
y_with_bias = (m * x) + b

# Plotting
plt.figure(figsize=(10, 6))
plt.plot(x, y_no_bias, label='Without Bias (y = mx)')
plt.plot(x, y_with_bias, label='With Bias (y = mx + b)')

plt.axhline(0, color='lightgrey', linestyle='--')  # Horizontal grey dashed line at y=0
plt.axvline(0, color='lightgrey', linestyle='--')  # Vertical grey dashed line at x=0
plt.title('Effect of Bias (intercept!) in a 2D Line')
plt.xlabel('Input (x)')
plt.ylabel('Output (y)')
plt.legend()
plt.show()





import matplotlib.pyplot as plt
import numpy as np

# Possible inputs and corresponding outputs for AND operation
inputs = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])
outputs = np.array([0, 0, 0, 1])

# Plotting the inputs
for point, output in zip(inputs, outputs):
    if output == 1:
        plt.scatter(point[0], point[1], color='blue', marker='o', s=100)  # Output 1
    else:
        plt.scatter(point[0], point[1], color='red', marker='x', s=100)  # Output 0

# Annotations and labels
plt.title('AND inputs and outputs ')
plt.xlabel('Input 1')
plt.ylabel('Input 2')
plt.xlim(-1, 2)
plt.ylim(-1, 2)
plt.grid(True, color='lightgrey')
plt.show()






import matplotlib.pyplot as plt
import numpy as np

def plot_decision_boundaries(inputs, outputs, slope_bias_pairs, ptitle='Decision boundaries'):
    """
    Plots decision boundaries for given inputs and outputs.

    Parameters:
    inputs (np.array): Array of input points.
    outputs (np.array): Array of output values corresponding to each input point.
    slope_bias_pairs (list of tuples): List of tuples where each tuple is (slope, bias).
    """
    # Plotting the inputs
    plt.figure(figsize=(8, 6))
    for point, output in zip(inputs, outputs):
        if output == 1:
            plt.scatter(point[0], point[1], color='blue', marker='o', s=100)  # Output 1
        else:
            plt.scatter(point[0], point[1], color='red', marker='x', s=100)  # Output 0

    # Plotting each decision boundary
    x = np.linspace(-1, 2, 100)
    for i, (m, b) in enumerate(slope_bias_pairs):
        y = m * x + b
        plt.plot(x, y, label=f'Line with Slope {m}, Bias {b}', linestyle='--', color=plt.cm.jet(i / len(slope_bias_pairs)))

    # Annotations and labels
    plt.title(ptitle)
    plt.xlabel('Input 1')
    plt.ylabel('Input 2')
    plt.legend()
    plt.xlim(-1, 2)
    plt.ylim(-1, 2)
    plt.grid(True, color='lightgrey')
    plt.show()

# Using the function for AND
inputs = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])
outputs = np.array([0, 0, 0, 1])
slope_bias_pairs = [(1.5, 0), (0.5, 0), (-1.0, 0)]

plot_decision_boundaries(inputs, outputs, slope_bias_pairs, ptitle='Decision boundaries without bias for AND')






slope_bias_pairs = [(-1, 1.5)]

plot_decision_boundaries(inputs, outputs, slope_bias_pairs, ptitle='Decision boundary with bias for AND')






outputs = np.array([1, 1, 1, 0])

plot_decision_boundaries(inputs, outputs, slope_bias_pairs, ptitle='Decision boundary with bias for NAND')






outputs = np.array([0, 1, 1, 1])
slope_bias_pairs = [(-1.0, 0), (-1, 0.5)]

plot_decision_boundaries(inputs, outputs, slope_bias_pairs, ptitle='Decision boundary with bias for OR')


















from scipy import stats
import numpy as np
import matplotlib.pyplot as plt

# This block just defines the function but doesn't do anything -- you have to call it, 
# e.g.: plot_regression_through_origin(sd=30.0, b=300.0, m=-10.0, minval=-1, maxval=50, nval=100)

# Note that I started off on a rabbit hole of thinking about R values for lines of best fit. 
# What really matters is error, which we will characterize as Mean Squared Error -- or MSE. 

import numpy as np

def calculate_r_from_line(actual_x, actual_y, slope, intercept, debug=False):
    """
    Calculates the Pearson correlation coefficient (R) between actual y values and y values predicted by a line.

    Parameters:
    actual_x (np.array): Array of x values.
    actual_y (np.array): Array of actual y values.
    slope (float): Slope of the line (model).
    intercept (float): Intercept of the line (model).

    Returns:
    float: Pearson correlation coefficient (R).
    """
    # Calculating predicted y values using the line equation
    predicted_y = slope * actual_x + intercept

    # Calculating Pearson's R
    correlation_matrix = np.corrcoef(actual_y, predicted_y)
    pearsons_r = correlation_matrix[0, 1]  # or correlation_matrix[1, 0] as the matrix is symmetric
    pearsons_r *= np.sign(slope) # 

    if debug:
        # Plotting actual vs. predicted values
        plt.figure(figsize=(8, 6))
        plt.scatter(actual_x, actual_y, color='blue', label='Actual Y Values')
        plt.scatter(actual_x, predicted_y, color='red', label='Predicted Y Values')
        plt.title('Actual vs. Predicted Y Values')
        plt.xlabel('X Values')
        plt.ylabel('Y Values')
        plt.legend()
        plt.title(f'Slope = {slope:.2f}, Intercept = {intercept:.2f}, R = {pearsons_r:.2f}')
        plt.show()

        print(actual_y)
        print(predicted_y)
    
    return pearsons_r, predicted_y

def plot_regression_through_origin(sd=1.0, b=10.0, m=10.0, minval=-5, maxval=5, nval=100,
                                  rseed=0, figwidth=8.0, figheight=6.0, ptitle="Pseudo data with lines of best fit"):
    """
    Generates a plot of pseudo data with a best fit line and a line through the origin.
    A red square is plotted at 0,0.
    
    Parameters:
    sd (float): Standard deviation of the noise.
    b (float): Intercept of the pseudo data line.
    m (float): Slope of the pseudo data line.
    minval (float): Minimum value of x in the pseudo data.
    maxval (float): Maximum value of x in the pseudo data.
    nval (int): Number of values in the pseudo data.
    rseed (int): random seed that can be set for reproducibility
    figwidth (float): figure width
    figheight (float): figure height 
    """
    # Seed for reproducibility and generating pseudo data
    np.random.seed(rseed)

    # Generating pseudo data
    x_data = np.linspace(minval, maxval, nval)
    y_data = m * x_data + b + np.random.normal(0, sd, x_data.size)

    # Calculating the best fit line with intercept
    slope, intercept, r_value, _, _ = stats.linregress(x_data, y_data)
    y_fit = slope * x_data + intercept

    # Calculating the best fitting line through the origin
    slope_origin = np.sum(x_data * y_data) / np.sum(x_data**2)
    y_fit_origin = slope_origin * x_data

    # ** not bothering with these anymore... ** 
    # Calculating R value for the line through the origin
    # Adjusted R-squared calculation
    # rss_origin = np.sum((y_data - y_fit_origin) ** 2)
    # tss_origin = np.sum(y_data**2)  # Total sum of squares from the origin
    # r_value_origin = np.sqrt(1 - rss_origin / tss_origin)  # Adjusted R-squared
    # # Adjusting the sign of R based on the slope
    # r_value_origin *= np.sign(slope_origin)
    
    
    # alternative method for calculating R, since other version is problematic
    # (was not actually problematic... but no longer using this for R; 
    #  however, still using it to get the predicted values from the line 
    #  equations so we can calculate MSE)
    # Parameters for the line (best)
    alt_r_best, pred_best = calculate_r_from_line(x_data, y_data, slope, intercept)
    alt_r_origin, pred_origin = calculate_r_from_line(x_data, y_data, slope_origin, 0)

    # MSE calculation
    mse_best = np.mean((y_data - pred_best)**2)
    mse_origin = np.mean((y_data - pred_origin)**2)
    mse_ratio = (mse_origin-mse_best) / mse_best * 100
    mse_ratio = (mse_origin/mse_best)
    
    # Plotting
    plt.figure(figsize=(figwidth, figheight))
    
    plt.scatter(x_data, y_data, color='blue', label='Pseudo Data')
    plt.plot(x_data, y_fit, color='red', label=f'Best Fit (y = {slope:.2f}x + {intercept:.2f})')
    plt.plot(x_data, y_fit_origin, color='green', label=f'Line Through Origin (y = {slope_origin:.2f}x)')

    # let's highlight the origin with a special mark and dashed lines. 
    plt.scatter([0], [0], color='red', marker='s', label='Point at Origin (0,0)')  # Red square at the origin
    plt.axhline(0, color='lightgrey', linestyle='--')  # Horizontal grey dashed line at y=0
    plt.axvline(0, color='lightgrey', linestyle='--')  # Vertical grey dashed line at x=0
    
    # Title and labels
    plt.title(ptitle)
    plt.xlabel('Input (x)')
    plt.ylabel('Output (y)')

    # Placing the legend and R value annotations
    legend = plt.legend()
    plt.gca().add_artist(legend)
    plt.text(1.05, 0.95, f'MSE ( best )={mse_best:.2f}', horizontalalignment='left', verticalalignment='top', transform=plt.gca().transAxes)
    plt.text(1.05, 0.90, f'MSE (origin)={mse_origin:.2f}', horizontalalignment='left', verticalalignment='top', transform=plt.gca().transAxes)
    plt.text(1.05, 0.825, f'MSE increase={mse_ratio:.2f} X ', horizontalalignment='left', verticalalignment='top', transform=plt.gca().transAxes)

    plt.show()
    
    #return pred_best, pred_origin, y_data






# Let's use it... First with a case where we get only small error with 0 bias
plot_regression_through_origin(sd=3.0, b=10.0, m=-10.0, minval=-1, maxval=50, nval=10)


# Let's do the same thing but generate 100 values instead of 10
plot_regression_through_origin(sd=3.0, b=10.0, m=-10.0, minval=-1, maxval=50, nval=100)





# Now let's make the bias (intercept) in the data quite substantial: 100
plot_regression_through_origin(sd=3.0, b=100.0, m=-10.0, minval=-1, maxval=50, nval=100)





plot_regression_through_origin(sd=30.0, b=300.0, m=-10.0, minval=-1, maxval=50, nval=100)





plot_regression_through_origin(sd=30.0, b=300.0, m=10.0, minval=-1, maxval=50, nval=100)





plot_regression_through_origin(sd=30.0, b=300.0, m=-10.0, minval=-50, maxval=50, nval=100)






