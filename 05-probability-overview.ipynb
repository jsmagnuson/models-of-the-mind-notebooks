{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72cc802c-41bc-4405-90e3-6fbecaa4ed0f",
   "metadata": {},
   "source": [
    "## Preliminaries: Understanding Logical Symbols in Probability\n",
    "\n",
    "Understanding the symbols used in probability is crucial for reading and interpreting mathematical statements. Below is a brief guide on how to read some of the most common logical symbols in the context of probability.\n",
    "\n",
    "### Identity or truth \n",
    "\n",
    "If event A has occurred, we simply state 'A'. This can be a little confusing. Let's compare it to *not*.\n",
    "\n",
    "### Logical NOT: $\\neg$ or $\\text{not}$\n",
    "\n",
    "The symbol $\\neg$ or the word \"not\" is used to denote the complement of an event A. Think of many possible states of the world, where in some of them, A is true (A has happened), while in others, A has not happened. These two sets are complements of each other, because we are saying for all states we care about, A will either happen or not. For example, we could talk about A being \"my bus arrived on time\" but not A ($\\neg A$) as \"my bus did not arrive on time\". For all times you took the bus, one of those is true, but not both. We can then talk about the probabilty of $A$ and $\\neg A$. \n",
    "\n",
    "Let's suppose that over the last year, I rode the bus 100 times, and it was on time 61 times. So the probability of A is 0.61, while the probability of $\\neg A$ would be 1 - 0.61 = 0.39. Note that $A + \\neg A = 1.0$, which is why they are complements. \n",
    "\n",
    "So $ P(\\neg A) $ should be read as \"the probability of not A\" or \"the probability of the complement of A\"; conceptually, again, this denotes the probabilty of A not happening. \n",
    "\n",
    "\n",
    "### Conditional Probability: $|$\n",
    "\n",
    "The vertical bar $|$ is used to denote conditional probability. It reads as \"given.\" For example, $ P(A | B)$ should be read as \"the probability of A given B.\" When we say B is \"given\" we mean it is true. So \"the probability of A given B\" means the probability of A when we assume B has happened. For example, we could talk about the probability of experiencing rain when the morning weather report tells us to expect rain. That is, we can talk about the probability of it actually raining *given* that the weather report said it would rain.\n",
    "\n",
    "### Logical AND: $\\cap$ or $\\text{and}$\n",
    "\n",
    "The symbol $\\cap$ or the word \"and\" is used to denote the intersection of two events A and B. For example, $ P(A \\cap B) $ should be read as \"the probability of A **and** B\" (that is, the probability that both are true). \n",
    "\n",
    "We could see this in real life if we had a rule that a faculty meeting could only proceed if *both* the department head **and** the associate department head are present (A = department head is present, B = associate head is present; we can only proceed when A and B are both true).\n",
    "\n",
    "### Logical OR: $\\cup$ or $\\text{or}$\n",
    "\n",
    "The symbol $\\cup$ or the word \"or\" is used to denote the *union* of two events A and B -- that is, all cases where either one of them is true. As sets, we would describe the cases where $A \\cup B$ is true to be: $\\{A, B\\}, \\{A, \\neg B\\}, \\{\\neg A, B\\}$. $A \\cup B$ is not true for $\\{\\neg A, \\neg B\\}$. \n",
    "\n",
    "So $ P(A \\cup B) $ should be read as \"the probability of A **or** B.\"\n",
    "\n",
    "We could see this in real life if we our faculty meeting rule was that the meeting could only proceed if *either* the department head **or** the associate department head are present (A = department head is present, B = associate head is present; we can only proceed when at least A or B are [or both] are true).\n",
    "\n",
    "\n",
    "### Exclusive OR (XOR): $\\oplus$\n",
    "\n",
    "The symbol $\\oplus$ denotes the exclusive OR, which means either A or B but not both.\n",
    "\n",
    "As sets, we would describe the cases where $A \\oplus B$ is true to be: $\\{A, \\neg B\\}, \\{\\neg A, B\\}$. $A \\oplus B$ is not true for $\\{\\neg A, \\neg B\\}$ or for $\\{A, B\\}$. \n",
    "\n",
    "So $ P(A \\oplus B) $ should be read as \"the probability of A XOR B\" (you really say \"ex or\"). \n",
    "\n",
    "---\n",
    "### Logic in programming\n",
    "\n",
    "These notions are also important in programming. Let's look at them in Python, which has very transparent logical operators. \n",
    "\n",
    "#### Understanding Logic Operators in Python\n",
    "\n",
    "In Python, logical operators are used to perform logical operations on variables and values. These operators evaluate expressions to `True` or `False`.\n",
    "\n",
    "## `and` Operator\n",
    "\n",
    "The `and` operator returns `True` if both expressions are true.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5bbd30e7-f7a7-48e0-b9a9-15fee184cd79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = True\n",
    "y = False\n",
    "result = x and y  # This will return False\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b40b72-e383-4af3-926e-8750a7f7e192",
   "metadata": {},
   "source": [
    "## `or` Operator\n",
    "\n",
    "The `or` operator returns `True` if at least one of the expressions is true.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9b4ac69f-fafd-4636-8065-e8875848eaf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = True\n",
    "y = False\n",
    "result = x or y  # This will return True\n",
    "result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89cbfa3-510f-430e-95bc-62a053a90170",
   "metadata": {},
   "source": [
    "## `not` Operator\n",
    "\n",
    "The `not` operator inverts the value of the expression following it. If the expression is `True`, `not` makes it `False` and vice versa.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "eff95cb9-d112-41a6-87e0-d3ec71994d6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = True\n",
    "result = not x  # This will return False\n",
    "result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99da8bb0-b27b-4d14-844b-839f2fdd72ce",
   "metadata": {},
   "source": [
    "## Comparison Operators\n",
    "\n",
    "Python also includes comparison operators (`==`, `!=`, `<`, `<=`, `>`, `>=`) that return Boolean values (`True` or `False`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a1cdafda-0756-4d76-9dbf-0eb0deef5d2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = 5\n",
    "y = 10\n",
    "result = x == y  # This will return False\n",
    "result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43083f6a-6c53-4476-8da5-662b1d8a0fcd",
   "metadata": {},
   "source": [
    "## Chaining Logical Operators\n",
    "\n",
    "You can chain multiple logical operators together to form more complex conditions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "23865faf-f171-45d1-8369-cf8ed2f32905",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = 5\n",
    "y = 10\n",
    "result = (x == y)  # This will return False\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cb8346c2-f46c-46f3-96e8-249fcd4c3e9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = 5\n",
    "y = 10\n",
    "z = 20\n",
    "result = x < y and y < z  # This will return True\n",
    "result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86d8745-f04c-4daf-8f1e-107181bfe691",
   "metadata": {},
   "source": [
    "Though it's a good practice to use parentheses to keep things clear (some programmers will scoff, but I think it's helpful). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "258e1851-fd7f-41ca-a076-3133b5cbe168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " First is False, second is True\n"
     ]
    }
   ],
   "source": [
    "x = 5\n",
    "y = 10\n",
    "result1 = (x == y)  # This will return False\n",
    "\n",
    "x = 5\n",
    "y = 10\n",
    "z = 20\n",
    "result2 = ((x < y) and (y < z))  # This will return True\n",
    "\n",
    "print(f' First is {result1}, second is {result2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7732f41-ee0e-41ed-a8e6-05c9027fdf34",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "Understanding these logical operators is essential for control flow in Python programming. \n",
    "They allow us to create complex conditions and decision-making structures. They can also \n",
    "really help you understand probability as you get used to using them. \n",
    "\n",
    "**Okay, let's move on to more advanced topics.**\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcd53e2-17cd-4a8f-b008-40555372a628",
   "metadata": {},
   "source": [
    "## Key Concepts in Probability\n",
    "\n",
    "### Introduction\n",
    "\n",
    "Probability is the branch of mathematics that deals with quantifying uncertainty. It's the toolset we use to describe phenomena where the outcome is not deterministic but can be any of a range of possibilities. Understanding probability is essential for fields like statistics, psychology, neuroscience, finance, and machine learning. This overview will equip you with the foundational knowledge required for a deeper understanding of Bayes' Theorem, which we will discuss in the next notebook.\n",
    "\n",
    "#### Example: Weather Forecasting\n",
    "\n",
    "In weather forecasting, we often hear terms like \"30% chance of rain,\" which is an application of probability. The forecast doesn't tell us definitively whether it will rain; instead, it quantifies the likelihood. It may help to think about probabilities as *relative frequencies*. A 30% chance or rain means something like \"out of 100 days with conditions like today's conditions, it will rain on 30 of them\" or \"out of 10,000 days with conditions like today's conditions, it will rain on 3,000 of them\".\n",
    "\n",
    "---\n",
    "\n",
    "### Sample Space $(S)$\n",
    "\n",
    "The sample space is the set of all possible outcomes (usually of an *experiment*, which can be as simple as tossing a coin).\n",
    "\n",
    "#### Example: Flipping a coin\n",
    "\n",
    "If you toss a coin, there are two possible outcomes, heads or tails. We describe the sample space as $S= \\{0, 1\\}$, where we assign one outcome the value of 0 and the other the value of 1.\n",
    "\n",
    "#### Example: Rolling a Die\n",
    "\n",
    "If you roll a standard six-sided die, the sample space $S = \\{1, 2, 3, 4, 5, 6\\}$.\n",
    "\n",
    "---\n",
    "\n",
    "### Event\n",
    "\n",
    "An event is a subset of the sample space. An event $A$ occurs if the outcome of the experiment is an element of $S$.\n",
    "\n",
    "#### Example: Scoring High on a Die Roll\n",
    "\n",
    "Events can be simple outcomes, like rolling a 6. But they can also be sets themselves. For example, we could define an event $A$ as \"rolling a number greater than 4\" on a standard six-sided die. Then $A = \\{5, 6\\}$.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f7a2c1-3b6e-4262-9d47-d40f921f45c8",
   "metadata": {},
   "source": [
    "\n",
    "### Probability Measure $(P)$\n",
    "\n",
    "The Probability Measure assigns a number between 0 and 1 to each event. $A$ represents an event and $S$ represents the sample space. The probability of the entire sample space $S$ is 1, and the probability of impossible events is 0.\n",
    "\n",
    "$$\n",
    "P(A) \\geq 0 \\quad \\text{and} \\quad P(S) = 1\n",
    "$$\n",
    "\n",
    "#### Example: Lottery Ticket\n",
    "\n",
    "If you buy a lottery ticket, the probability of winning the jackpot might be $1$ in $10,000,000$ or $P(A) = \\frac{1}{10,000,000}$. The probability of not winning is very close to 1.\n",
    "\n",
    "#### Example: Raffle\n",
    "\n",
    "At a town celebration, there is a raffle. There are 100 tickets. Only 4 people buy tickets. Bob buys 50, Sally buys 25, Renatta buys 15, and Jose buys 10. They write their names on each ticket, and then the tickets are put in a hat and shaken up. The mayor draws a ticket. What are the possible outcomes? The winner will be Bob, Sally, Renatta, or Jose. So there are 4 possible outcomes. Their probabilties (since we have this convenient total number of 100 tickets) are 0.5, 0.25, 0.15, and 0.1. These have to sum to 1.0, just like the number of tickets in the hat has to be the same as the number of tickets sold.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### Priors\n",
    "\n",
    "In probability and statistics, a \"prior\" is a pre-existing belief about an uncertain situation. Essentially, it's your initial guess before considering new evidence. Priors can be based on historical data, expert opinion, or some other form of background knowledge.\n",
    "\n",
    "#### Example: Fair Coin\n",
    "\n",
    "If you assume that a coin is \"fair,\" your prior for the probability of getting heads is $0.5$, and likewise for tails. This is based on the belief that a fair coin has equal chances for heads and tails. \n",
    "\n",
    "#### Informal Testing\n",
    "\n",
    "To informally test whether a coin is fair, you might simply flip it a number of times and observe the outcomes. If the coin is indeed fair, you would expect to see approximately as many heads as tails over a large number of flips. However, this method is not precise.\n",
    "\n",
    "#### Statistical Testing with Binomial Distribution\n",
    "\n",
    "For a more rigorous assessment, you can use the statistics of *binomial* distributions (cases where there are only 2 possible events or outcomes). If you flip the coin $n$ times and observe $k$ heads, the probability of this happening with a fair coin can be calculated using the binomial probability formula:\n",
    "\n",
    "$$\n",
    "P(k \\text{ heads in } n \\text{ flips}) = \\binom{n}{k} \\times 0.5^k \\times 0.5^{(n-k)}\n",
    "$$\n",
    "\n",
    "Here, $\\binom{n}{k}$ is the binomial coefficient, representing the number of ways to get $k$ successes in $n$ trials. See more on this below.\n",
    "\n",
    "After calculating this probability, if the result is extremely low, you may have grounds to reject the hypothesis that the coin is fair. Typically, a threshold (often 5% or 1%) is set for this purpose. Note that our estimate will become more precise as we increase the number of flips. (Also, the threshold depends on context. For example, if we are minting a new coin, we might be satisfied with a coin that is not perfectly weighted. However, if we are in charge of selecting coins to use for the National Football League coin toss, we would want it to be well weighted. Think about real-life examples where the *stakes* are different.)\n",
    "\n",
    "**Understanding the Binomial Coefficient in the Binomial Probability Formula**\n",
    "\n",
    "In the formula for calculating the probability of observing $k$ heads in $n$ flips of a fair coin,\n",
    "\n",
    "$$\n",
    "P(k \\text{ heads in } n \\text{ flips}) = \\binom{n}{k} \\times 0.5^k \\times 0.5^{(n-k)}\n",
    "$$\n",
    "\n",
    "The term \\(\\binom{n}{k}\\) is, again, the \"binomial coefficient.\" This term represents the number of different ways you can\n",
    "choose $k$ successes (in this case, heads) out of $n$ trials (coin flips).\n",
    "\n",
    "\\(\\binom{n}{k}\\) tells you how many different sequences of heads and tails will result in exactly $k$ heads when you flip a \n",
    "coin $n$  times. For example, if $n=3$  and $k=2$ , then $\\binom{3}{2} = 3$ because there are three different ways to get exactly 2 heads in 3 coin flips: HHT, HTH, or THH.\n",
    "\n",
    "The binomial coefficient is calculated using the following formula (which Abhijith tried to explain during class; sorry!):\n",
    "\n",
    "$$\n",
    "\\binom{n}{k} = \\frac{n!}{k! \\times (n-k)!}\n",
    "$$\n",
    "\n",
    "Here, $n!$ denotes the factorial of $n$, which is the product of all positive integers up to $n$ (e.g., if $n=3$, $n! = 1 \\times 2 \\times 3 = 6$).\n",
    "\n",
    "**Role in the Binomial Probability Formula**\n",
    "\n",
    "The binomial coefficient serves as a \"weight\" that accounts for the different ways \\(k\\) successes can happen in \\(n\\) trials, making it a crucial part of the binomial probability formula.\n",
    "\n",
    "\n",
    "##### Probability of 4 Heads in 4 Flips with a Fair Coin\n",
    "\n",
    "Let's try calculating the probability of getting 4 heads in a row with a fair coin. Again, we use the binomial probability formula:\n",
    "\n",
    "$$\n",
    "P(4 \\text{ heads in 4 flips}) = \\binom{4}{4} \\times 0.5^4 \\times 0.5^{(4-4)}\n",
    "$$\n",
    "\n",
    "Here, $\\binom{4}{4}$ is the binomial coefficient, which is 1 in this case. The probability of getting a head in each individual flip is 0.5, and since we are considering 4 flips, this becomes $0.5^4$.\n",
    "\n",
    "After performing the calculation, we find:\n",
    "\n",
    "$$\n",
    "P(4 \\text{ heads in 4 flips}) = 1 \\times 0.0625 \\times 1 = 0.0625\n",
    "$$\n",
    "\n",
    "So, there is a 6.25% chance of getting 4 heads in a row with a fair coin. While 6.25% is small, it's maybe not as small as we might have expected. We should discuss low-probability events in class. \n",
    "\n",
    "Let's do it in python in the code block below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b3b8b29c-3476-49b2-b1d1-ebc55e4d8373",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0625"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from math import comb\n",
    "\n",
    "# Number of trials (n) and number of successes (k)\n",
    "n = 4  # Number of coin flips\n",
    "k = 4  # Number of heads\n",
    "\n",
    "# Probability of getting heads or tails with a fair coin\n",
    "p_head = 0.5\n",
    "\n",
    "# Calculate the probability using the binomial distribution formula\n",
    "probability = comb(n, k) * (p_head ** k) * ((1 - p_head) ** (n - k))\n",
    "probability\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0306a86f-3793-412e-8da2-76bb5f1e2547",
   "metadata": {},
   "source": [
    "---\n",
    "#### Example: Fair Six-Sided Die\n",
    "\n",
    "Similarly, if you have a standard six-sided die and assume that it's \"fair,\" your prior for each outcome from 1 to 6 would be $\\frac{1}{6}$. This is based on the symmetry and equal weight distribution of a standard six-sided die.\n",
    "\n",
    "---\n",
    "\n",
    "### Updating Priors\n",
    "\n",
    "Priors are updated with new data through the use of conditional probabilities and Bayes' Theorem. After the update, the prior becomes a \"posterior,\" which is a refined probability estimate that incorporates the new evidence. This process of updating is the cornerstone of Bayesian inference.\n",
    "\n",
    "---\n",
    "\n",
    "### Conditional Probability: $P(A|B)$\n",
    "\n",
    "Conditional probability is the probability of $A$ occurring given that $B$ has already occurred.\n",
    "\n",
    "$$\n",
    "P(A|B) = \\frac{P(A \\cap B)}{P(B)}\n",
    "$$\n",
    "\n",
    "Again, we read this as \"the probability of A given B\", which means we are considering the probability of A being true if we assume B is true.\n",
    "\n",
    "#### Example: Medical Diagnosis\n",
    "\n",
    "If a person has certain symptoms (event $B$), the probability they have a particular disease (event $A$) might be higher, given those symptoms.\n",
    "\n",
    "---\n",
    "\n",
    "### Independence\n",
    "\n",
    "Events $A$ and $B$ are independent if the occurrence of one does not affect the occurrence of the other.\n",
    "\n",
    "$$\n",
    "P(A \\cap B) = P(A) \\times P(B)\n",
    "$$\n",
    "\n",
    "How do we read this? The probability of A **and** B is the probability of A times the probability of B. For example, if I decide I will walk to work every other Monday during the fall semsester, the probability of me walking to work on a Monday is 0.5. However, this has no impact on the probability that it will rain on Mondays. So if the probability of daytime rain in the fall semester is 0.1 (1 day out of 10), the probability that I will walk to work and it will rain is 0.5 * 0.1.\n",
    "\n",
    "In contrast, if I'm only 20% likely to walk to work if it's raining, these are not independent anymore. Now whether I walk to work is affected by whether it is raining. \n",
    "\n",
    "### Example: Coin Tosses\n",
    "\n",
    "If you toss a coin twice, the outcome of the first toss is independent of the outcome of the second toss.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f222d80-e876-4f32-a363-740de354606f",
   "metadata": {},
   "source": [
    "\n",
    "## When to Multiply and When to Add Probabilities\n",
    "\n",
    "### Multiplication Rule\n",
    "\n",
    "You multiply probabilities when events are independent.\n",
    "\n",
    "$$\n",
    "P(A  \\cap B) = P(A) \\times P(B)\n",
    "$$\n",
    "\n",
    "#### Example: Cards and/or coins\n",
    "\n",
    "Getting 2 heads in a row flipping a fair coin = $0.5 \\times 05$. \n",
    "\n",
    "---\n",
    "\n",
    "**Correcting the example from class...**\n",
    "*In class I originally presented drawing an Ace and a King as an example where we would multiply, and I just said $P(Ace) \\times P(King)$. This was not quite correct. Oops. Here's the revised text. *\n",
    "\n",
    "What if we get an Ace and *then* a King? **Naomi** pointed us to the right answer in class by saying if we wanted to think of this as 4/52 x 4/52 (since there are 4 Aces and 4 Kings in a 52-card deck), we would have to draw the Ace and then replace it in the deck and then reshuffle before drawing the second card. In that case, yes, the probabilities are independent, just like coin tosses, so we would get (4/52) x (4/52) = 0.0059 (0.59%). \n",
    "\n",
    "**Abhijith** correctly told me that if we do this without replacement, we should do (4/52) x (4/51) = 0.0060 (very slightly more probable). Note that in this case we *must shuffle the deck before the second card is drawn.* This is where I was getting confused.\n",
    "\n",
    "Where I was confused was with the idea of the two cards being on top of the deck -- cards 1 and cards 2. Here, the sequences are not independent anymore. The King was already in second position. In this case, we have to treat this as a 2-card draw, since we are essentially drawing the simultaneously (the King remains the 2nd card, so the next draw is not random). So let's consider the case where we draw 2 cards from a deck. What is the probability of getting and Ace and a King if we do not care about order? To calculate this, we have to think about how many 2-card combinations there are. There are (52 x 51)/2 = 1326 combinations. Of those, 16 would be Ace-King combinations (since there are 4 Aces and 4 Kings). So if you draw two cards from a deck, the probability that 1 is an Ace and 1 is a king is 16/1326 = 0.012 (1.2%). \n",
    "  \n",
    "---\n",
    "\n",
    "### Addition Rule\n",
    "\n",
    "You add probabilities when considering mutually exclusive events.\n",
    "\n",
    "$$\n",
    "P(A \\cup B) = P(A) + P(B)\n",
    "$$\n",
    "\n",
    "#### Example: Multiple Choice Quiz\n",
    "\n",
    "In a multiple-choice question with 4 choices, where only one answer is correct, the probability of guessing correctly is $P(A) = \\frac{1}{4}$. The probability of guessing incorrectly is $P(B) = \\frac{3}{4}$. The sum $P(A) + P(B) = 1$ covers all possible outcomes.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32dee7e2-9651-44b3-978f-0da9da9952df",
   "metadata": {},
   "source": [
    "### Optional advanced topic: \n",
    "#### Using Logarithms to Simplify Probability Computations\n",
    "\n",
    "In probability and statistics, you often encounter products of probabilities, especially in scenarios involving independent events or likelihood functions. These products can quickly become too small or too large to handle, causing numerical instability in calculations. Logarithms provide a way to simplify these computations.\n",
    "\n",
    "#### Why Use Logarithms?\n",
    "\n",
    "Logarithms convert multiplications into additions and divisions into subtractions. This makes the arithmetic more manageable and helps to avoid numerical issues like underflow and overflow.\n",
    "\n",
    "$$\n",
    "\\log(a \\times b) = \\log(a) + \\log(b)\n",
    "$$\n",
    "$$\n",
    "\\log\\left(\\frac{a}{b}\\right) = \\log(a) - \\log(b)\n",
    "$$\n",
    "\n",
    "##### Example: Independent Events\n",
    "\n",
    "Suppose we want to calculate the probability of observing a specific sequence in a Bernoulli (binomial) trial with success probability $ p $ and failure probability $ 1 - p $.\n",
    "\n",
    "The probability of observing, say, \"success, failure, success\" (or heads, tails, heads) would be $ p \\times (1-p) \\times p $.\n",
    "\n",
    "Using logarithms, we can simplify this to:\n",
    "\n",
    "$$\n",
    "\\log(p \\times (1-p) \\times p) = \\log(p) + \\log(1-p) + \\log(p)\n",
    "$$\n",
    "\n",
    "To get it back to a probabilty, we would exponate the result, e.g.: \n",
    "\n",
    "$$\n",
    "z' = \\log(p) + \\log(1-p) + \\log(p)\n",
    "$$\n",
    "\n",
    "Now $d$ is the log probability of observing the sequence. We get the probability by converting it back:\n",
    "\n",
    "$$\n",
    "z = exp(z')\n",
    "$$\n",
    "\n",
    "Now $z$ is the sequence probability. \n",
    "\n",
    "### Numerical Example: Using Probabilities vs Logarithms\n",
    "\n",
    "Let's consider a numerical example where the probability of success is 0.7 and the probability of failure is 0.3. This could mean a weighted coin where the probability of heads is 0.7, a quality control scenario (where a worker detecting a defective product could be 'success'), or a medical testing scenario (where 0.7 is the probability of detecting disease if the patient has it).\n",
    "\n",
    "#### Using Probabilities\n",
    "\n",
    "The probability of the sequence \"success, failure, success\" can be calculated as follows:\n",
    "\n",
    "$$\n",
    "0.7 \\times 0.3 \\times 0.7 = 0.147\n",
    "$$\n",
    "\n",
    "#### Using Logarithms\n",
    "\n",
    "We can also calculate the log-probability of the same sequence:\n",
    "\n",
    "$$\n",
    "\\log(0.7) + \\log(0.3) + \\log(0.7) \\approx -1.917\n",
    "$$\n",
    "\n",
    "#### Converting Back to Original Probability Scale\n",
    "\n",
    "To convert the log-probability back to the original probability scale, we take the exponent:\n",
    "\n",
    "$$\n",
    "\\exp(-1.917) \\approx 0.147\n",
    "$$\n",
    "\n",
    "Both methods yield the same result, confirming the equivalence of the two approaches. Using logarithms can be particularly useful in practice for avoiding numerical underflow and for computational efficiency.\n",
    "\n",
    "#### Now let's do this in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c7ca103b-4b90-49b9-a459-fceb1c9921b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability: 0.147000, Log prob: -1.917323, Exp log prob: 0.147000\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "# Given probabilities\n",
    "p_success = 0.7  # Probability of success\n",
    "p_failure = 0.3  # Probability of failure (1 - p_success)\n",
    "\n",
    "# Calculate the probability of the sequence \"success, failure, success\"\n",
    "probability = p_success * p_failure * p_success\n",
    "\n",
    "# Calculate the log-probability of the sequence \"success, failure, success\"\n",
    "log_probability = math.log(p_success) + math.log(p_failure) + math.log(p_success)\n",
    "\n",
    "# Convert the log-probability back to the original probability scale\n",
    "exp_log_probability = math.exp(log_probability)\n",
    "\n",
    "print(f'Probability: {probability:.6f}, Log prob: {log_probability:.6f}, \\\n",
    "Exp log prob: {exp_log_probability:.6f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773819e1-83d6-4b26-bc33-9b1b87282494",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Advantages of working with logarithms\n",
    "\n",
    "These advantages accrue when you are working with many computations; this may be relevant if you work with complex Bayesian models or neural network analyses.\n",
    "\n",
    "1. **Computational Stability**: Log-probabilities mitigate the risk of numerical underflow, which can occur when multiplying many small probabilities together.\n",
    "2. **Speed**: Addition is generally faster than multiplication in terms of computational time.\n",
    "3. **Summation**: When dealing with products of probabilities, converting to log-probabilities allows you to use summation techniques, which can be more efficient.\n",
    "\n",
    "#### Summary\n",
    "\n",
    "Logarithms are a powerful tool for simplifying complex probability calculations. They are especially useful in scenarios involving the multiplication of many probabilities, where numerical issues are likely to occur."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984ab6fb-a830-41b8-98ed-70707f437565",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "Understanding these foundational concepts is crucial for diving deeper into the world of probability and statistics, especially as they lay the groundwork for advanced topics like Bayes' Theorem. These principles are not just theoretical; they are used in everyday decision-making (though maybe not as often as they should be...) and in various scientific disciplines."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
